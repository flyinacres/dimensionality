{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":396802,"sourceType":"datasetVersion","datasetId":175990}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://azad-wolf.medium.com/latent-space-representation-a-hands-on-tutorial-on-autoencoders-in-tensorflow-57735a1c0f3f","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport pathlib\n\n\n## create train and validation datasets\nDB_PATH = \"//kaggle//input//fashion-product-images-small//images/\"\nBUFFER_SIZE = 10000\nBATCH_SIZE = 1000\nIMG_WIDTH = 60\nIMG_HEIGHT = 60\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:49:32.019219Z","iopub.execute_input":"2024-05-10T08:49:32.019571Z","iopub.status.idle":"2024-05-10T08:49:32.024291Z","shell.execute_reply.started":"2024-05-10T08:49:32.019545Z","shell.execute_reply":"2024-05-10T08:49:32.023436Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pwd\n\n!ls -U //kaggle/input/fashion-product-images-small/images | head -4\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-10T08:38:04.032774Z","iopub.execute_input":"2024-05-10T08:38:04.033134Z","iopub.status.idle":"2024-05-10T08:38:04.682414Z","shell.execute_reply.started":"2024-05-10T08:38:04.033105Z","shell.execute_reply":"2024-05-10T08:38:04.681458Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working\n31973.jpg\n30778.jpg\n19812.jpg\n22735.jpg\nls: write error: Broken pipe\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef load(image_file):\n    image = tf.io.read_file(image_file)\n    image = tf.image.decode_jpeg(image,channels=3)\n\n    input_image = tf.cast(image, tf.float32)\n    return input_image\n\ndef random_crop(input_image):\n    cropped_image = tf.image.random_crop(\n      input_image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n\n    return cropped_image\n\ndef resize(input_image):\n    input_image = tf.image.resize(input_image, [IMG_HEIGHT, IMG_WIDTH],\n                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    return input_image\n\ndef normalize(input_image):\n    input_image = (input_image / 255)\n    return input_image\n\n@tf.function()\ndef random_jitter(input_image):\n    input_image = random_crop(input_image)\n    if tf.random.uniform(()) > 0.5:\n        input_image = tf.image.flip_left_right(input_image)\n        \n    return input_image\n\ndef load_image_train(image_file):\n    input_image = load(image_file)\n    #input_image = random_jitter(input_image)\n    input_image = resize(input_image)\n    input_image = normalize(input_image)\n\n    return input_image,input_image\n\ndef load_image_test(image_file):\n    input_image = load(image_file)\n    #input_image = random_jitter(input_image)\n    input_image = resize(input_image)\n    input_image = normalize(input_image)\n    return input_image,input_image\n\n\ndata_dir = pathlib.Path(DB_PATH)\nimage_count = len(list(data_dir.glob('*.jpg')))\nprint(f\"image count {image_count}\")\ndataset = tf.data.Dataset.list_files(DB_PATH)\n\n\nval_size = int(image_count * 0.2)\ntrain_ds = dataset.skip(val_size)\nval_ds = dataset.take(val_size)\n\nprint(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\n\n\ntrain_ds = train_ds.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntrain_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n\nval_ds = val_ds.map(load_image_test)\nval_ds = val_ds.batch(BATCH_SIZE)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:50:35.925567Z","iopub.execute_input":"2024-05-10T08:50:35.925943Z","iopub.status.idle":"2024-05-10T08:50:36.242790Z","shell.execute_reply.started":"2024-05-10T08:50:35.925914Z","shell.execute_reply":"2024-05-10T08:50:36.241461Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"image count 44441\n0\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = tf.data.Dataset.list_files(DB_PATH)\n\nval_size = int(image_count * 0.2)\ntrain_ds = dataset.skip(val_size)\nval_ds = dataset.take(val_size)\n\ntrain_ds.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\ntrain_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:52:24.869935Z","iopub.execute_input":"2024-05-10T08:52:24.870324Z","iopub.status.idle":"2024-05-10T08:52:24.902362Z","shell.execute_reply.started":"2024-05-10T08:52:24.870297Z","shell.execute_reply":"2024-05-10T08:52:24.901388Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tf.data.Dataset.list_files(DB_PATH+\"*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:52:29.447415Z","iopub.execute_input":"2024-05-10T08:52:29.447781Z","iopub.status.idle":"2024-05-10T08:52:34.423319Z","shell.execute_reply.started":"2024-05-10T08:52:29.447757Z","shell.execute_reply":"2024-05-10T08:52:34.422303Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"},"metadata":{}}]},{"cell_type":"code","source":"val_ds.take(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:55:16.388127Z","iopub.execute_input":"2024-05-10T08:55:16.388677Z","iopub.status.idle":"2024-05-10T08:55:16.395595Z","shell.execute_reply.started":"2024-05-10T08:55:16.388650Z","shell.execute_reply":"2024-05-10T08:55:16.394723Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<_TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"},"metadata":{}}]},{"cell_type":"code","source":"list(val_ds.as_numpy_iterator())[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:52:44.810595Z","iopub.execute_input":"2024-05-10T08:52:44.810971Z","iopub.status.idle":"2024-05-10T08:52:44.825750Z","shell.execute_reply.started":"2024-05-10T08:52:44.810946Z","shell.execute_reply":"2024-05-10T08:52:44.824287Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"b'//kaggle//input//fashion-product-images-small//images/'"},"metadata":{}}]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nfor images,targets in val_ds.take(1):\n    for i in range(45):\n      ax = plt.subplot(3, 15, i + 1)\n      plt.imshow(images[i].numpy().astype(\"float32\"))\n      plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T08:52:52.778162Z","iopub.execute_input":"2024-05-10T08:52:52.778473Z","iopub.status.idle":"2024-05-10T08:52:52.906683Z","shell.execute_reply.started":"2024-05-10T08:52:52.778453Z","shell.execute_reply":"2024-05-10T08:52:52.905839Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images,targets \u001b[38;5;129;01min\u001b[39;00m val_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m45\u001b[39m):\n\u001b[1;32m      4\u001b[0m       ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m15\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:326\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    324\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disallow_iteration()\n\u001b[0;32m--> 326\u001b[0m first_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_first_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _TensorIterator(\u001b[38;5;28mself\u001b[39m, first_dim)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:334\u001b[0m, in \u001b[0;36mTensor._get_first_dim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a tensor with unknown shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape:\n\u001b[0;32m--> 334\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a scalar tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a tensor with unknown first dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a scalar tensor."],"ename":"TypeError","evalue":"Cannot iterate over a scalar tensor.","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 0 Axes>"},"metadata":{}}]}]}